CNN_TPE_BrainTumor_Reproduction

Reproduction of a full pipeline for brain tumor classification using a
Convolutional Neural Network (CNN) optimized with Tree-Structured Parzen
Estimator (TPE).
This project includes dataset preparation, model definition,
hyperparameter optimization, training, evaluation, and fine-tuning.

Repository Structure

    CNN_TPE_BrainTumor_Reproduction/
    │
    ├── train_cnn_tpe.py                   # CNN model training and TPE hyperparameter optimization
    
    │
    ├── environment_cpu.yml                # Conda environment (CPU)
    ├── environment_gpu.yml                # Conda environment (GPU)
    │
    ├── notebooks/
    │   ├── 1_data_preparation             # Interactive dataset creation
    │   ├── 2_hyperparameter_search      # TPE optimization workflow
    │   ├── 3_train_evaluate            # Model training and evaluation
    │
    ├── src/
    │   ├── model_architectures             # CNN architectures and layers
    │   ├── tpe_functions                   # Search space definitions and optimization logic
    │   ├── training_utils                  # Training loop, callbacks, metrics
    │   ├── dataset_utils                 # Loaders, augmentation, transformations
    │
    ├── trained_models/
    │   ├── CNN_TPE_BestModel.pth          # Best model checkpoint
    │   ├── CNN_TPE_BestParams.json        # Best TPE hyperparameters
    │
    ├── example_inputs/
    │   ├── sample_train_data.csv          # Sample formatted training file
    │   ├── sample_test_data.csv           # Sample formatted testing file
    │
    └── README.md

Installation

GPU environment

    conda env create -f environment_gpu.yml
    conda activate cnn_tpe_env

CPU environment

    conda env create -f environment_cpu.yml
    conda activate cnn_tpe_env

Install local modules:

    pip install -e .

Usage

1. Dataset Processing

    python process_dataset     --data_dir ./raw_data     --output_dir ./processed_data     --img_size 224

2. Run TPE Optimization

    python train_cnn_tpe     --train_dir ./processed_data/train     --val_dir ./processed_data/val     --epochs 30     --trials 50     --save_dir trained_models/

3. Evaluate Model

    python evaluate_model     --test_dir ./processed_data/test     --model trained_models/CNN_TPE_BestModel.pth     --params trained_models/CNN_TPE_BestParams.json

4. Fine-Tune Model

    python fine_tune_model     --new_data ./new_dataset     --model trained_models/CNN_TPE_BestModel.pth     --epochs 10

Input Format

The dataset should follow:

    dataset/
    │── train/
    │── val/
    │── test/
          ├── glioma/
          ├── meningioma/
          ├── pituitary/
          ├── no_tumor/

Output

Dataset Processing

-   Normalized and augmented dataset directories
-   Class statistics

TPE Optimization

-   Best hyperparameters (JSON)
-   Best model checkpoint (pth)
-   Training logs and metric curves

Evaluation

-   Accuracy, precision, recall, F1-score
-   Confusion matrix
-   Classification report

Workflow Description

1. Data Loading and Cleaning

2. Hyperparameter Optimization (TPE)

3. CNN Training

4. Model Evaluation

Configuration

Editable parameters in:

-   tpe_functions
-   model_architectures
-   train_cnn_tpe

End-to-End Execution

    python process_dataset
    python train_cnn_tpe
    python evaluate_model

Notebooks

Dependencies

Python 3.8+
PyTorch
Optuna
NumPy
Pandas
scikit-learn
Matplotlib
torchvision

License

For research and educational use.
